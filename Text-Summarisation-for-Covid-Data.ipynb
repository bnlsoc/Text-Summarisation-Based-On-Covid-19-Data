{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Some basic poitnts about NLP</H4>\n",
    "<br>\n",
    "Natural Language Processing or NLP is basically a sub-field of artificial intelligence in which we make computer system learn, analyse and generate natural language\n",
    "<hr style=\"height: 2pt;background-color: red\">\n",
    "NLP : consists of NLU and NLG<br>\n",
    "       NLU - Natural Language Understanding\n",
    "       NLG - Natural Language Generation\n",
    "<h5>5 different phases of NLU and NLG</h5>\n",
    "<ol>\n",
    "<li>Lexical Processing:- tokenisation. morphological analysis, processing on individual words</li>\n",
    "<li>Syntactic Processing :- Internal representation of the text, example a parse tree representation.</li>\n",
    "<li>Semantic Processing :- Clarifying the meaning of the word, meaning of words may be different in different context, for example, Federal Bank, bank of a river</li>\n",
    "<li>Disposal/Pragmatic Processing:- Former deals with emotions (like text to speech) and Pragmatic deals with stories (eg John is a monk. He goes to Church Daily. He is a Catholic.)</li>\n",
    "</ol>\n",
    "<hr style=\"height: 2pt;background-color: blue\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Text Summmarisation System</h1>\n",
    "<hr style=\"height: 2pt;background-color: green\">\n",
    "Condensing a longer document into a short concise document without losing the core information\n",
    "<br>\n",
    "Based on input, it can be a sinlge document or multi-document summary\n",
    "<br>Based on the Purpose: Like some documents are generic or some from one domain (like summarising covid-19 dataset is domain)\n",
    "<br>Query Based: User asks questions.\n",
    "<h6>Extractive (just retains main sentences) and Abstractive (writing the summary in own words)</h6>\n",
    "\n",
    "\n",
    "<It's assumed you are familiar with supervised and unsupervised learning>\n",
    "<hr style=\"height: 2pt;background-color: red\">\n",
    "Starting with Code (Explained with comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Text summariation by frequency of words </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gauri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gauri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "#Importing the Libraries\n",
    "#NLTK-natural language toolkit for natural language processing\n",
    "#CORPUS- Collection of Documents, eg Wall Street Journal CORPUS\n",
    "#using stop-words CORPUS, stop-words are words like of, are, is etc, \n",
    "#which occur more frequently and have no semantic meaning\n",
    "#We need to tokenize the words because we need to compute the frequency of each word\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import documents\n",
    "f = open(('./trial_covid_dataset.txt'),\"r\")\n",
    "text = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So, we have stored the document's text into text variable\n",
    "#Preprocessing the data : Very Important to avoid overfit or underfit\n",
    "\n",
    "#Step-1 We tokenize each sentence\n",
    "\n",
    "sent_tokens = nltk.sent_tokenize(text)\n",
    "word_tokens = nltk.word_tokenize(text)\n",
    "\n",
    "#Step-2 We convert to lower case\n",
    "word_tokens_lower = [word.lower() for word in word_tokens]\n",
    "\n",
    "#Step-3 remove stopwords\n",
    "stopWords = list(set(stopwords.words('english'))) #getting all stopwords of English and storing in StopWords\n",
    "word_tokens_refined = [word for word in word_tokens_lower if word not in stopWords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "FreqTable = {} #defining a dictionary\n",
    "for word in word_tokens_refined:\n",
    "    if word in FreqTable:\n",
    "        FreqTable[word]+=1\n",
    "    else:\n",
    "        FreqTable[word]=1\n",
    "\n",
    "##This is here major part of summary comes to play\n",
    "sentence_value = {}\n",
    "for sentence in sent_tokens:\n",
    "    sentence_value[sentence]=0\n",
    "    for word,freq in FreqTable.items():\n",
    "        if word in sentence.lower():\n",
    "            sentence_value[sentence]+=freq\n",
    "#How it works on the basis of frequency can be visualised in the console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For inding the score of each sentence\n",
    "\n",
    "#Finding the average\n",
    "sum = 0\n",
    "for sentence in sentence_value:\n",
    "    sum = sum + sentence_value[sentence]\n",
    "average = sum/len(sentence_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll be using it to generate the summary\n",
    "summary = ''\n",
    "for sentence in sent_tokens:\n",
    "    if sentence_value[sentence]>average:\n",
    "        summary=summary+sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success from two leading coronavirus vaccine programs likely means other frontrunners will also show strong protection against COVID-19, Bill Gates said Tuesday.The fact that two coronavirus vaccines recently showed strong protection against COVID-19 bodes well for other leading programs led by AstraZeneca, Novavax, and Johnson & Johnson, Bill Gates said Tuesday.The billionaire Microsoft founder and philanthropist said it will be easier to boost manufacturing and distribute these other shots to the entire world, particularly developing nations.The vaccine space has seen a flurry of good news in recent days, marked by overwhelming success in late-stage trials by both Pfizer and Moderna.\"With the very good news from Pfizer and Moderna, we think it's now likely that AstraZeneca, Novavax, and Johnson & Johnson will also likely show very strong efficacy,\" Gates told journalist Andrew Ross Sorkin.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Voila! Your first Text Summarisation is Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.4,
   "position": {
    "height": "244px",
    "left": "695.8px",
    "right": "20px",
    "top": "6px",
    "width": "327px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
